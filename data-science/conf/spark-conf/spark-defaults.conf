# Configuración para Spark:

# Configuración del master
spark.master                     spark://spark-master:7077
spark.driver.memory              1g
spark.executor.memory            1g
spark.executor.cores             1
spark.default.parallelism        2
spark.sql.shuffle.partitions     2

# Configuración para integración con Hadoop/HDFS
spark.hadoop.fs.defaultFS        hdfs://namenode:9000

# Configuración para integración con Hive
spark.sql.warehouse.dir          hdfs://namenode:9000/user/hive/warehouse
spark.sql.hive.metastore.version 2.3.0
spark.sql.hive.metastore.jars    path
spark.sql.hive.metastore.jars.path /opt/hive/lib/*
spark.sql.catalogImplementation  hive
spark.hive.metastore.uris        thrift://hive-metastore:9083

# Configuración para el History Server
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://namenode:9000/spark-logs
spark.history.fs.logDirectory    hdfs://namenode:9000/spark-logs

# Gestión de memoria y recursos
spark.memory.fraction            0.6
spark.memory.storageFraction     0.5

# Serialización
spark.serializer                 org.apache.spark.serializer.KryoSerializer

# Optimización de rendimiento
spark.speculation                false
spark.dynamicAllocation.enabled  false

# Configuración para el driver UI
spark.ui.port                    4040
spark.ui.reverseProxy            true
